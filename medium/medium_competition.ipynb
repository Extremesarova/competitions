{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMqBVrwYAlfg"
   },
   "source": [
    "# Importing needed packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "BSo65XyCAlfh"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/lightgbm/__init__.py:46: UserWarning: Starting from version 2.2.1, the library file in distribution wheels for macOS is built by the Apple Clang (Xcode_8.3.3) compiler.\n",
      "This means that in case of installing LightGBM from PyPI via the ``pip install lightgbm`` command, you don't need to install the gcc compiler anymore.\n",
      "Instead of that, you need to install the OpenMP library, which is required for running LightGBM on the system with the Apple Clang compiler.\n",
      "You can install the OpenMP library by the following command: ``brew install libomp``.\n",
      "  \"You can install the OpenMP library by the following command: ``brew install libomp``.\", UserWarning)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import json\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from html.parser import HTMLParser\n",
    "import lightgbm as lgb\n",
    "import tqdm\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GkONB47nAlfh"
   },
   "source": [
    "# Setting global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "hp-DcUw7Alfh"
   },
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "TITLE_NGRAMS = (1, 2)  # for tf-idf on titles\n",
    "CONTENT_NGRAMS = (1, 2)  # for tf-idf on contents\n",
    "MAX_FEATURES = 100000  # for tf-idf\n",
    "LGB_TRAIN_ROUNDS = 60  # num. iteration to train LightGBM\n",
    "LGB_NUM_LEAVES = 255  # max number of leaves in LightGBM trees\n",
    "MEAN_TEST_TARGET = 4.33328  # what we got by submitting all zeros\n",
    "RIDGE_WEIGHT = 0.6  # weight of Ridge predictions in a blend with LightGBM\n",
    "LGB_WEIGHT = 0.4\n",
    "PATH_TO_DATA = '/Users/Extremesarova/repos/competitions/medium/data'\n",
    "PATH_TO_SAVE_DIR = '/Users/Extremesarova/repos/competitions/medium/additional_data'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rLQQ-wolAlfi"
   },
   "source": [
    "# Defining auxilary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "b_UqnZT2Alfi"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MLStripper(HTMLParser):\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "        self.strict = False\n",
    "        self.convert_charrefs = True\n",
    "        self.fed = []\n",
    "\n",
    "    def handle_data(self, d):\n",
    "        self.fed.append(d)\n",
    "\n",
    "    def get_data(self):\n",
    "        return ' '.join(self.fed)\n",
    "\n",
    "\n",
    "def strip_tags(html):\n",
    "    s = MLStripper()\n",
    "    s.feed(html)\n",
    "    return s.get_data()\n",
    "\n",
    "\n",
    "def read_json_line(line=None):\n",
    "    result = None\n",
    "    try:\n",
    "        result = json.loads(line)\n",
    "    except Exception as e:\n",
    "        # Find the offending character index:\n",
    "        idx_to_replace = int(str(e).split(' ')[-1].replace(')', ''))\n",
    "        # Remove the offending character:\n",
    "        new_line = list(line)\n",
    "        new_line[idx_to_replace] = ' '\n",
    "        new_line = ''.join(new_line)\n",
    "        return read_json_line(line=new_line)\n",
    "    return result\n",
    "\n",
    "\n",
    "def extract_features_and_write(path_to_data, path_to_save, inp_filename, is_train=True):\n",
    "    titles = []\n",
    "    contents = []\n",
    "    dates = []\n",
    "    authors = []\n",
    "    features = ['content', 'published', 'title', 'author']\n",
    "    prefix = 'train' if is_train else 'test'\n",
    "    os.makedirs(os.path.dirname(path_to_save), exist_ok=True)\n",
    "    feature_files = [open(os.path.join(path_to_save,\n",
    "                                       '{}_{}.txt'.format(prefix, feat)),\n",
    "                          'w', encoding='utf-8')\n",
    "                     for feat in features]\n",
    "\n",
    "    with open(os.path.join(path_to_data, inp_filename), encoding='utf-8') as inp_json_file:\n",
    "\n",
    "        for line in tqdm.tqdm(inp_json_file, desc=f\"Reading {prefix} json files\"):\n",
    "            json_data = read_json_line(line)\n",
    "\n",
    "            title = json_data['title'].replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ').replace('\\xa0', ' ')\n",
    "            content = strip_tags(\n",
    "                json_data['content'].replace('\\n', ' ').replace('\\t', ' ').replace('\\r', ' ').replace('\\xa0', ' '))\n",
    "            published = json_data['published']\n",
    "            author = json_data['meta_tags']['author']\n",
    "            authors_name = json_data['meta_tags']['author']\n",
    "\n",
    "            titles.append(title)\n",
    "            contents.append(content)\n",
    "            dates.append(published)\n",
    "            authors.append(authors_name)\n",
    "\n",
    "    dic = {'content': contents, 'published': dates, 'title': titles, 'author': authors}\n",
    "    for feature in features:\n",
    "        filename = prefix + \"_\" + feature + \".txt\"\n",
    "        with open(os.path.join(path_to_save, filename), 'wb') as fp:\n",
    "            pickle.dump(dic[feature], fp)\n",
    "\n",
    "    return titles, contents, dates, authors\n",
    "\n",
    "\n",
    "# Time features\n",
    "def add_time_features(dates):\n",
    "    scaler = StandardScaler()\n",
    "    hour = scaler.fit_transform(np.array([date.hour for date in dates]).reshape(-1, 1))\n",
    "    weekday = scaler.fit_transform(np.array([date.weekday() for date in dates]).reshape(-1, 1))\n",
    "    morning = scaler.fit_transform(((hour >= 7) & (hour <= 11)).astype('int').reshape(-1, 1))\n",
    "    day = scaler.fit_transform(((hour >= 12) & (hour <= 18)).astype('int').reshape(-1, 1))\n",
    "    evening = scaler.fit_transform(((hour >= 19) & (hour <= 23)).astype('int').reshape(-1, 1))\n",
    "    night = scaler.fit_transform(((hour >= 0) & (hour <= 6)).astype('int').reshape(-1, 1))\n",
    "    weekend_temp = np.array([date.weekday() for date in dates]).reshape(-1, 1)\n",
    "    weekend = scaler.fit_transform(((weekend_temp >= 5) & (weekend_temp <= 6)).astype('int').reshape(-1, 1))\n",
    "\n",
    "    feature_names = ['morning', 'day', 'evening', 'night', 'weekday']\n",
    "    time_features = pd.DataFrame(list(zip(morning.flatten(),\n",
    "                                          day.flatten(),\n",
    "                                          evening.flatten(),\n",
    "                                          night.flatten(),\n",
    "                                          weekend.flatten())), columns=feature_names)\n",
    "    sparse_time_features = csr_matrix(time_features.values)\n",
    "    return sparse_time_features, feature_names\n",
    "\n",
    "\n",
    "def write_submission_file(prediction, filename,\n",
    "                          path_to_sample=os.path.join(PATH_TO_SAVE_DIR,\n",
    "                                                      'sample_submission.csv')):\n",
    "    submission = pd.read_csv(path_to_sample, index_col='id')\n",
    "\n",
    "    submission['log_recommends'] = prediction\n",
    "    submission.to_csv(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yte08nD5Alfj"
   },
   "source": [
    "# Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBXh6I6wAlfj",
    "outputId": "9db01ca6-5176-468f-d2aa-ef1bbb911bee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reading train json files: 62313it [04:28, 231.74it/s]\n",
      "Reading test json files: 34645it [02:40, 215.33it/s]\n"
     ]
    }
   ],
   "source": [
    "train_titles, train_contents, train_dates, train_authors = extract_features_and_write(PATH_TO_DATA,\n",
    "                                                                                      PATH_TO_SAVE_DIR,\n",
    "                                                                                      'train.json',\n",
    "                                                                                      is_train=True)\n",
    "test_titles, test_contents, test_dates, test_authors = extract_features_and_write(PATH_TO_DATA,\n",
    "                                                                                  PATH_TO_SAVE_DIR,\n",
    "                                                                                  'test.json',\n",
    "                                                                                  is_train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XKsFXVDiAlfk"
   },
   "source": [
    "# Doing TF-IDF vectorization for articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "eQCPFDnIAlfk"
   },
   "outputs": [],
   "source": [
    "vectorizer_params = {'ngram_range': CONTENT_NGRAMS,\n",
    "                     'max_features': MAX_FEATURES,\n",
    "                     'tokenizer': lambda s: s.split(),\n",
    "                     'stop_words': ENGLISH_STOP_WORDS,\n",
    "                    }\n",
    "vectorizer_article = TfidfVectorizer(**vectorizer_params)\n",
    "X_train_article = vectorizer_article.fit_transform(train_contents)\n",
    "X_test_article = vectorizer_article.transform(test_contents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DS_4LQ45Alfk"
   },
   "source": [
    "# Doing TF-IDF vectorization for titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "genquqjIAlfl"
   },
   "outputs": [],
   "source": [
    "vectorizer_params = {'ngram_range': TITLE_NGRAMS,\n",
    "                         'max_features': MAX_FEATURES,\n",
    "                         'tokenizer': lambda s: s.split(),\n",
    "                         'stop_words': ENGLISH_STOP_WORDS\n",
    "                    }\n",
    "vectorizer_title = TfidfVectorizer(**vectorizer_params)\n",
    "X_train_title = vectorizer_title.fit_transform(train_titles)\n",
    "X_test_title = vectorizer_title.transform(test_titles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C9ZxJ5lGAlfl"
   },
   "source": [
    "# Preparing time features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ZeDZ0PjEAlfl"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "train_times = pd.to_datetime([date['$date'] for date in train_dates])\n",
    "test_times = pd.to_datetime([date['$date'] for date in test_dates])\n",
    "\n",
    "X_train_time_features_sparse, time_feature_names = add_time_features(train_times)\n",
    "X_test_time_features_sparse, _ = add_time_features(test_times)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Hu1Z6b2jAlfm"
   },
   "source": [
    "# Doing bag of authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "FhSYT14zAlfm"
   },
   "outputs": [],
   "source": [
    "authors = np.unique(train_authors + test_authors)\n",
    "enc = OneHotEncoder(handle_unknown='ignore')\n",
    "enc.fit(authors.reshape(-1, 1))\n",
    "enc.categories_\n",
    "X_train_author_sparse = enc.transform(np.array(train_authors).reshape(-1, 1)).toarray()\n",
    "X_test_author_sparse = enc.transform(np.array(test_authors).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qIHooxOfAlfm"
   },
   "source": [
    "# Preparing additional features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "NIGCO5ZUAlfm"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/sklearn/utils/validation.py:595: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "train_len = [len(article) for article in train_contents]\n",
    "test_len = [len(article) for article in test_contents]\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_len_sparse = scaler.fit_transform(np.array(train_len).reshape(-1, 1))\n",
    "X_test_len_sparse = scaler.fit_transform(np.array(test_len).reshape(-1, 1))\n",
    "\n",
    "X_train_sparse = hstack([X_train_article, X_train_title,\n",
    "                             X_train_author_sparse,\n",
    "                             X_train_time_features_sparse, X_train_len_sparse]).tocsr()\n",
    "\n",
    "X_test_sparse = hstack([X_test_article, X_test_title,\n",
    "                            X_test_author_sparse,\n",
    "                            X_test_time_features_sparse, X_test_len_sparse]).tocsr()\n",
    "\n",
    "train_target = pd.read_csv(os.path.join(PATH_TO_DATA, 'train_log1p_recommends.csv'),\n",
    "                               index_col='id')\n",
    "y_train = train_target['log_recommends'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HdqwIayWAlfn"
   },
   "source": [
    "# Doing Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "Eu1y78tPAlfn"
   },
   "outputs": [],
   "source": [
    "# alpha_values = np.logspace(-2, 2, 20)\n",
    "ridge = Ridge(random_state=SEED, alpha=0.01)\n",
    "# logit_grid_searcher = GridSearchCV(estimator=ridge, param_grid={'alpha': alpha_values}, scoring='neg_mean_absolute_error', n_jobs=4, cv=3, verbose=1)\n",
    "ridge.fit(X_train_sparse, y_train)\n",
    "# final_model = logit_grid_searcher.best_estimator_\n",
    "ridge_test_pred = ridge.predict(X_test_sparse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkwCSNfVAlfo"
   },
   "source": [
    "# Doing Light GBM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jw-g3S0ZAlfo"
   },
   "outputs": [],
   "source": [
    "lgb_x_train = lgb.Dataset(X_train_sparse.astype(np.float32),\n",
    "                              label=np.log1p(y_train))\n",
    "param = {'num_leaves': LGB_NUM_LEAVES,\n",
    "             'objective': 'mean_absolute_error',\n",
    "             'metric': 'mae'}\n",
    "bst_lgb = lgb.train(param, lgb_x_train, LGB_TRAIN_ROUNDS, verbose_eval=5)\n",
    "lgb_test_pred = np.expm1(bst_lgb.predict(X_test_sparse.astype(np.float32)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nMgwKfwYAlfo"
   },
   "source": [
    "# Doing blending and saving results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rAzC-uwxAlfo"
   },
   "outputs": [],
   "source": [
    "mix_pred = LGB_WEIGHT * lgb_test_pred + RIDGE_WEIGHT * ridge_test_pred\n",
    "mix_test_pred_modif = mix_pred + MEAN_TEST_TARGET - y_train.mean()\n",
    "\n",
    "write_submission_file(mix_test_pred_modif, f'submission_alice_{AUTHOR}.csv')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "medium-competition.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
